{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "5378117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split \n",
    "import utils\n",
    "# Optimization module in scipy\n",
    "from scipy import optimize\n",
    "from sklearn import metrics\n",
    "# tells matplotlib to embed plots within the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a766be",
   "metadata": {},
   "source": [
    "# Clasification of adults that have an income larger than 50K\n",
    "\n",
    "# Using a Neural Network\n",
    "------------------------------------------\n",
    "*******************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16486a0",
   "metadata": {},
   "source": [
    "# Preprocesing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4468278",
   "metadata": {},
   "source": [
    "### Loading Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "2cfc3c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = pd.read_csv('adult_processed_x.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "355c29c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y= pd.read_csv('adult_processed_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "5a473d06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 88)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "X= data_x.to_numpy()\n",
    "print(X.shape)\n",
    "print(X.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4bd04a20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 1)\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "y = data_y.to_numpy()\n",
    "print(y.shape)\n",
    "print(y.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12eed7a2",
   "metadata": {},
   "source": [
    "### Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "2673aa01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples:\t32561\n",
      "Number of training samples:\t16280\n",
      "Number of validation samples:\t8140\n",
      "Number of test samples:\t8141\n",
      "(16280, 88)\n",
      "(8140, 88)\n",
      "(8141, 88)\n"
     ]
    }
   ],
   "source": [
    "N = len(X)\n",
    "N_train = int(0.5*N)      # The model  parameters for the network are adjusted using this set\n",
    "N_val = int(0.25*N) # Use to tune parameters in the model. And avoid overfitting to the trainning set.  \n",
    "N_test = N-N_train-N_val\n",
    "\n",
    "# set random seed:\n",
    "np.random.seed(0) \n",
    "\n",
    "# create a random permutation for splitting into training, validation and test\n",
    "randperm = np.random.permutation(N)\n",
    "\n",
    "# split into training and test\n",
    "train_idx = randperm[:N_train]\n",
    "val_idx = randperm[N_train:(N_train+N_val)]\n",
    "test_idx = randperm[(N_train+N_val):]\n",
    "\n",
    "Xtrain,Xval, Xtest = X[train_idx, :],X[val_idx, :], X[test_idx, :]\n",
    "ytrain,yval, ytest = y[train_idx], y[val_idx] , y[test_idx]\n",
    "\n",
    "print('Total number of samples:\\t%d' % N)\n",
    "print('Number of training samples:\\t%d' % N_train)\n",
    "print('Number of validation samples:\\t%d' % N_val)\n",
    "print('Number of test samples:\\t%d' % N_test)\n",
    "print(Xtrain.shape)\n",
    "print(Xval.shape)\n",
    "print(Xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2f3890",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d56c6e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== MY CODE HERE ASSIG.4 ======================\n",
    "\n",
    "def randInitializeWeights(L_in, L_out, epsilon_init=0.12):\n",
    "    # Assignment 4\n",
    "    W = np.zeros((L_out, 1 + L_in))\n",
    "    # ====================== MY CODE HERE ======================\n",
    "    W = np.random.rand(L_out, 1 + L_in) * 2 * epsilon_init - epsilon_init\n",
    "    # ============================================================\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4afc75de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== MY CODE HERE ASSIG.4 ======================\n",
    "def matrix_of_y(y,num_labels):\n",
    "    n = y.shape[0]\n",
    "    y_v = np.zeros([n,num_labels])\n",
    "    if(y_v.shape[1]==1):\n",
    "        return y\n",
    "    else:\n",
    "        for r in range (n):\n",
    "            y_v[r,y[r]] = 1\n",
    "        return  y_v  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "256ea39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== MY CODE HERE ASSIG.3 ======================\n",
    "def sigmoid(z):\n",
    "    z = np.array(z)\n",
    "    g = np.reciprocal((np.exp(z*-1))+1)\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "e5e77018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== MY CODE HERE ASSIG.4 ======================\n",
    "def sigmoidGradient(z):\n",
    "    \n",
    "    g = np.zeros(z.shape)\n",
    "    g_t = sigmoid(z)\n",
    "    g= g_t*(1-g_t)\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "a06e74ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== MY CODE HERE ASSIG.4 ADAPTED======================\n",
    "def nnCostFunction(nn_params,\n",
    "                   input_layer_size,\n",
    "                   hidden_layer_size,\n",
    "                   num_labels,\n",
    "                   X, y, lambda_=0.0):\n",
    "    \n",
    "    Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)],\n",
    "                        (hidden_layer_size, (input_layer_size + 1)))\n",
    "\n",
    "    Theta2 = np.reshape(nn_params[(hidden_layer_size * (input_layer_size + 1)):],\n",
    "                        (num_labels, (hidden_layer_size + 1)))\n",
    "\n",
    "    m = y.size\n",
    "    J = 0\n",
    "    Theta1_grad = np.zeros(Theta1.shape)\n",
    "    Theta2_grad = np.zeros(Theta2.shape)\n",
    "\n",
    "    \n",
    "    # ====================== MY CODE HERE ASSIG.4======================\n",
    "    #Calculate hypothesis \n",
    "    a1 = np.concatenate([np.ones((m, 1)), X], axis=1) # add x0 = 1\n",
    "    z2 = np.matmul(Theta1,a1.T)\n",
    "    a2 = sigmoid(z2)\n",
    "    a2 = np.concatenate([np.ones((1, a2.shape[1])), a2], axis=0)\n",
    "    z3 = np.matmul(Theta2,(a2))\n",
    "    a3 = sigmoid(z3)\n",
    "    almost_zero=1e-10\n",
    "    hyp = a3.T\n",
    "    y_v = matrix_of_y(y,num_labels)\n",
    "\n",
    "    #Calculate cost function. \n",
    "    J = (-1 / m) * np.sum((np.log(hyp+almost_zero) * y_v) + np.log(1 - hyp+almost_zero) * (1 - y_v)) \n",
    "\n",
    "    #Calculate regularized cost function.\n",
    "    temp_theta1 = Theta1[:,1:]\n",
    "    temp_theta2 = Theta2[:,1:]\n",
    "\n",
    "    J_reg_factor = (lambda_/(2*m))*(np.sum(np.square(temp_theta1))+np.sum(np.square(temp_theta2)))\n",
    "    J_reg = J+J_reg_factor\n",
    "    \n",
    "    delta_3 = hyp - y_v+almost_zero\n",
    "    delta_2 = delta_3.dot(Theta2)[:, 1:] * sigmoidGradient(a1.dot(Theta1.T))\n",
    "\n",
    "    Delta1 = delta_2.T.dot(a1)\n",
    "    Delta2 = delta_3.T.dot(a2.T)\n",
    "    # Add regularization to gradient\n",
    "    Theta1_grad = (1 / m) * Delta1\n",
    "    Theta1_grad[:, 1:] = Theta1_grad[:, 1:] + (lambda_ / m) * Theta1[:, 1:]\n",
    "    \n",
    "    Theta2_grad = (1 / m) * Delta2\n",
    "    Theta2_grad[:, 1:] = Theta2_grad[:, 1:] + (lambda_ / m) * Theta2[:, 1:]\n",
    "      \n",
    "    grad = np.concatenate([Theta1_grad.ravel(), Theta2_grad.ravel()])\n",
    "    \n",
    "    return J_reg, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "80f61479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== MY CODE HERE ASSIG.4 ======================\n",
    "def randomInititalWeights(input_layer_size, hidden_layer_size,num_labels):\n",
    "    initial_Theta1 = randInitializeWeights(input_layer_size, hidden_layer_size)\n",
    "    initial_Theta2 = randInitializeWeights(hidden_layer_size, num_labels)\n",
    "    # Unroll parameters\n",
    "    initial_nn_params = np.concatenate([initial_Theta1.ravel(), initial_Theta2.ravel()], axis=0)\n",
    "    return initial_nn_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "e2c3192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fowardPropagation(inputSet, theta1_input,theta2_input ):\n",
    "    m= inputSet[:,0].size\n",
    "    a1 = np.concatenate([np.ones((m, 1)), inputSet], axis=1) # add x0 = 1\n",
    "    z2 = np.matmul(theta1_input,a1.T)\n",
    "    a2 = sigmoid(z2)\n",
    "    a2 = np.concatenate([np.ones((1, a2.shape[1])), a2], axis=0)\n",
    "    z3 = np.matmul(theta2_input,(a2))\n",
    "    a3 = sigmoid(z3)\n",
    "    hyp = a3.T\n",
    "    return hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "0c889822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispayPerformance(inputSetX, inputSetY,theta1_input,theta2_input,thresh):\n",
    "    hyp_out = fowardPropagation(inputSetX,Theta1_train,Theta2_train)\n",
    "    \n",
    "    hyp_= [0 if value < thresh else 1 for value in hyp_out]\n",
    "    accuracy_score= metrics.accuracy_score (inputSetY, hyp_)\n",
    "    p_score = metrics.precision_score(inputSetY, hyp_)\n",
    "    r_score = metrics.recall_score(inputSetY, hyp_) \n",
    "    f_score = metrics.f1_score(inputSetY, hyp_) \n",
    "\n",
    "#     print(accuracy_score)\n",
    "#     print(p_score)\n",
    "#     print(r_score)\n",
    "#     print(f_score)\n",
    "    return accuracy_score, f_score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97263832",
   "metadata": {},
   "source": [
    "# Pre-Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12075ad1",
   "metadata": {},
   "source": [
    "### Checking if data is biased \n",
    "\n",
    "The data is biased \n",
    "Only 25% of the data erans more than 50K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "351d8010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples with income above 50K:\t7841\n",
      "Total number of samples :\t\t\t32561\n"
     ]
    }
   ],
   "source": [
    "large_income=y[y==1].size\n",
    "print('Total number of samples with income above 50K:\\t%d' % large_income)\n",
    "print('Total number of samples :\\t\\t\\t%d' % y.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47f3d70",
   "metadata": {},
   "source": [
    "### Model representation\n",
    "\n",
    "Our neural network is shown in the following figure.\n",
    "\n",
    "It has 3 layers - an input layer, a hidden layer and an output layer.\n",
    "- Input layer has 88 layer units.\n",
    "- Hidden layer X layer units.\n",
    "- Output layer has 2 layer units. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "dfbbe904",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_size  = Xtrain.shape[1]    \n",
    "num_labels = 1          # where 1 means (income => 50k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123194b2",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7572d28c",
   "metadata": {},
   "source": [
    " ### Calculate optimal weights for neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "9efa109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuralNetwork(training_steps,lambda_in,hidden_layer_size):\n",
    "    options= {'maxiter': training_steps}\n",
    "    lambda_ = lambda_in\n",
    "    \n",
    "    \n",
    "    costFunction = lambda p: nnCostFunction(p, input_layer_size,\n",
    "                                        hidden_layer_size,\n",
    "                                        num_labels, Xtrain, ytrain, lambda_)\n",
    "    \n",
    "    initial_rand_params= randomInititalWeights(input_layer_size,hidden_layer_size,num_labels)\n",
    "    \n",
    "    res = optimize.minimize(costFunction,\n",
    "                            initial_rand_params,\n",
    "                            jac=True,\n",
    "                            method='TNC',\n",
    "                            options=options)\n",
    "    # get the solution of the optimization\n",
    "    nn_params = res.x\n",
    "    # Obtain Theta1 and Theta2 back from nn_params\n",
    "    Theta1_train = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)],\n",
    "                        (hidden_layer_size, (input_layer_size + 1)))\n",
    "\n",
    "    Theta2_train= np.reshape(nn_params[(hidden_layer_size * (input_layer_size + 1)):],\n",
    "                        (num_labels, (hidden_layer_size + 1)))\n",
    "    return Theta1_train,Theta2_train,nn_params\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d058fe",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0592a1",
   "metadata": {},
   "source": [
    "### Calculating optimal hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f2e970a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35917733 0.34585221 0.3458451  0.33555055 0.34228337 0.33554765\n",
      " 0.34920861]\n"
     ]
    }
   ],
   "source": [
    "hiden_units_values=np.array([10,20,40,75, 80,85,90,100,120])\n",
    "train_error = np.zeros(hiden_units_values.size)\n",
    "val_error =np.zeros(hiden_units_values.size)\n",
    "step_units_input = 50\n",
    "lambda_in = 1\n",
    "for i in range(hiden_units_values.size):\n",
    "    \n",
    "    theta1,theta2,initial_nn_params = neuralNetwork(step_units_input,lambda_in,hiden_units_values[i])\n",
    "    train_error[i],_=nnCostFunction(initial_nn_params,input_layer_size,hiden_units_values[i],num_labels,Xtrain,ytrain)\n",
    "    val_error[i],_=nnCostFunction(initial_nn_params,input_layer_size,hiden_units_values[i],num_labels,Xval,yval)\n",
    "\n",
    "print(train_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "ba4eb277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35917733 0.34585221 0.3458451  0.33555055 0.34228337 0.33554765\n",
      " 0.34920861]\n",
      "[0.36487608 0.34942707 0.3494849  0.33663762 0.3458197  0.33727962\n",
      " 0.35422483]\n"
     ]
    }
   ],
   "source": [
    "print(train_error)\n",
    "print(val_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
