{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5378117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# tells matplotlib to embed plots within the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a766be",
   "metadata": {},
   "source": [
    "# Clasification of adults that have an income larger than 50K\n",
    "\n",
    "# Using a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4468278",
   "metadata": {},
   "source": [
    "### Loading Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2cfc3c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = pd.read_csv('adult_processed_x.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "355c29c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y= pd.read_csv('adult_processed_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5a473d06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 88)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "X= data_x.to_numpy()\n",
    "print(X.shape)\n",
    "print(X.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5aeee597",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 1)\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "y = data_y.to_numpy()\n",
    "print(y.shape)\n",
    "print(y.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4eebcf4",
   "metadata": {},
   "source": [
    "## Checking if data is biased \n",
    "\n",
    "The data is biased \n",
    "Only 25% of the data erans more than 50K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3f058012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7841\n"
     ]
    }
   ],
   "source": [
    "print(y[y==1].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a778f0",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6571a02a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples:\t32561\n",
      "Number of training samples:\t16280\n",
      "Number of validation samples:\t8140\n",
      "Number of test samples:\t8141\n",
      "(16280, 88)\n",
      "(8140, 88)\n",
      "(8141, 88)\n"
     ]
    }
   ],
   "source": [
    "N = len(X)\n",
    "N_train = int(0.5*N)      # The model  parameters for the network are adjusted using this set\n",
    "N_val = int(0.25*N) # Use to tune parameters in the model. And avoid overfitting to the trainning set.  \n",
    "N_test = N-N_train-N_val\n",
    "\n",
    "# set random seed:\n",
    "np.random.seed(0) \n",
    "\n",
    "# create a random permutation for splitting into training, validation and test\n",
    "randperm = np.random.permutation(N)\n",
    "\n",
    "# split into training and test\n",
    "train_idx = randperm[:N_train]\n",
    "val_idx = randperm[N_train:(N_train+N_val)]\n",
    "test_idx = randperm[(N_train+N_val):]\n",
    "\n",
    "Xtrain,Xval, Xtest = X[train_idx, :],X[val_idx, :], X[test_idx, :]\n",
    "ytrain,yval, ytest = y[train_idx], y[val_idx] , y[test_idx]\n",
    "\n",
    "print('Total number of samples:\\t%d' % N)\n",
    "print('Number of training samples:\\t%d' % N_train)\n",
    "print('Number of validation samples:\\t%d' % N_val)\n",
    "print('Number of test samples:\\t%d' % N_test)\n",
    "print(Xtrain.shape)\n",
    "print(Xval.shape)\n",
    "print(Xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90000fd9",
   "metadata": {},
   "source": [
    "## Model representation\n",
    "\n",
    "Our neural network is shown in the following figure.\n",
    "\n",
    "It has 3 layers - an input layer, a hidden layer and an output layer.\n",
    "- Input layer has 88 layer units.\n",
    "- Hidden layer 88 layer units.\n",
    "- Output layer has 2 layer units. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1478197c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_size  = Xtrain.shape[1]  \n",
    "hidden_layer_size = input_layer_size   \n",
    "num_labels = 1          # where 1 means (income => 50k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e79078",
   "metadata": {},
   "source": [
    "## Random Initialization of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6e9b0e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== MY CODE HERE ASSIG.4 ======================\n",
    "\n",
    "def randInitializeWeights(L_in, L_out, epsilon_init=0.12):\n",
    "    # Assignment 4\n",
    "    W = np.zeros((L_out, 1 + L_in))\n",
    "    # ====================== MY CODE HERE ======================\n",
    "    W = np.random.rand(L_out, 1 + L_in) * 2 * epsilon_init - epsilon_init\n",
    "    # ============================================================\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "95f079e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Neural Network Parameters ...\n"
     ]
    }
   ],
   "source": [
    "# ====================== MY CODE HERE ASSIG.4 ======================\n",
    "\n",
    "initial_Theta1 = randInitializeWeights(input_layer_size, hidden_layer_size)\n",
    "initial_Theta2 = randInitializeWeights(hidden_layer_size, num_labels)\n",
    "# Unroll parameters\n",
    "initial_nn_params = np.concatenate([initial_Theta1.ravel(), initial_Theta2.ravel()], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8a05df",
   "metadata": {},
   "source": [
    "## Feedforward and cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "099792dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== MY CODE HERE ASSIG.4 ======================\n",
    "def matrix_of_y(y,num_labels):\n",
    "    \"\"\"\n",
    "    parameters\n",
    "    y : array_like\n",
    "            Dataset labels. A vector of shape (m,).\n",
    "    returns\n",
    "    y_v: matrix_like\n",
    "            Dataset labels in vector shape\n",
    "    \"\"\"\n",
    "    y_v = np.zeros([y.size,num_labels])\n",
    "    for r in range (y_v.shape[0]):\n",
    "        y_v[r,y[r]] = 1\n",
    "    return  y_v  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333a6112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== MY CODE HERE ASSIG.3 ======================\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute sigmoid function given the input z.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    z : array_like\n",
    "        The input to the sigmoid function. This can be a 1-D vector \n",
    "        or a 2-D matrix. \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    g : array_like\n",
    "        The computed sigmoid function. g has the same shape as z, since\n",
    "        the sigmoid is computed element-wise on z.    \n",
    "   \"\"\"\n",
    "    z = np.array(z)\n",
    "    g = np.reciprocal((np.exp(z*-1))+1)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee7f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidGradient(z):\n",
    "    \n",
    "    g = np.zeros(z.shape)\n",
    "\n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    #g_t = np.reciprocal((np.exp(z*-1))+1)\n",
    "    g_t = sigmoid(z)\n",
    "    g= g_t*(1-g_t)\n",
    "\n",
    "\n",
    "    # =============================================================\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fa95e257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnCostFunction(nn_params,\n",
    "                   input_layer_size,\n",
    "                   hidden_layer_size,\n",
    "                   num_labels,\n",
    "                   X, y, lambda_=0.0):\n",
    "    \n",
    "    Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)],\n",
    "                        (hidden_layer_size, (input_layer_size + 1)))\n",
    "\n",
    "    Theta2 = np.reshape(nn_params[(hidden_layer_size * (input_layer_size + 1)):],\n",
    "                        (num_labels, (hidden_layer_size + 1)))\n",
    "\n",
    "    m = y.size\n",
    "    J = 0\n",
    "    Theta1_grad = np.zeros(Theta1.shape)\n",
    "    Theta2_grad = np.zeros(Theta2.shape)\n",
    "\n",
    "    # ====================== MY CODE HERE ASSIG.4======================\n",
    "    #Calculate hypothesis \n",
    "    a1 = np.concatenate([np.ones((m, 1)), X], axis=1) # add x0 = 1\n",
    "    z2 = np.matmul(Theta1,a1.T)\n",
    "    a2 = sigmoid(z2)\n",
    "    a2 = np.concatenate([np.ones((1, a2.shape[1])), a2], axis=0)\n",
    "    z3 = np.matmul(Theta2,(a2))\n",
    "    a3 = sigmoid(z3)\n",
    "    hyp = a3.T\n",
    "    y_v = matrix_of_y(y,num_labels)\n",
    "\n",
    "    #Calculate cost function. \n",
    "    J_i= np.zeros(m)\n",
    "    for i in range (m):    \n",
    "        J_i[i] = -(1/m)*(y_v[i]@(np.log(hyp[i]))+(1-y_v[i])@(np.log(1-hyp[i]))) \n",
    "    J = np.sum(J_i)\n",
    "    \n",
    "    #Calculate regularized cost function.\n",
    "    temp_theta1 = Theta1[:,1:]\n",
    "    temp_theta2 = Theta2[:,1:]\n",
    "\n",
    "    J_reg_factor = (lambda_/(2*m))*(np.sum(np.square(temp_theta1))+np.sum(np.square(temp_theta2)))\n",
    "    J_reg = J+J_reg_factor\n",
    "    \n",
    "    delta_3 = hyp - y_v\n",
    "    delta_2 = delta_3.dot(Theta2)[:, 1:] * sigmoidGradient(a1.dot(Theta1.T))\n",
    "\n",
    "    Delta1 = delta_2.T.dot(a1)\n",
    "    Delta2 = delta_3.T.dot(a2.T)\n",
    "    \n",
    "    # Add regularization to gradient\n",
    "    Theta1_grad = (1 / m) * Delta1\n",
    "    Theta1_grad[:, 1:] = Theta1_grad[:, 1:] + (lambda_ / m) * Theta1[:, 1:]\n",
    "    \n",
    "    Theta2_grad = (1 / m) * Delta2\n",
    "    Theta2_grad[:, 1:] = Theta2_grad[:, 1:] + (lambda_ / m) * Theta2[:, 1:]\n",
    "      \n",
    "    grad = np.concatenate([Theta1_grad.ravel(), Theta2_grad.ravel()])\n",
    "    \n",
    "#     print(\"----######-------\")\n",
    "#     print()\n",
    "#     print(\"----X_test-------\")\n",
    "#     print(X_test.shape)\n",
    "\n",
    "    return J_reg, grad\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "13881132",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_345289/2398087027.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m J, _ = nnCostFunction(initial_nn_params, input_layer_size, hidden_layer_size,\n\u001b[0m\u001b[1;32m      3\u001b[0m                    num_labels, Xtrain, ytrain, lambda_)\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cost at parameters (randomly initialize): %.6f '\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mJ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_345289/476342717.py\u001b[0m in \u001b[0;36mnnCostFunction\u001b[0;34m(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, lambda_)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# add x0 = 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTheta1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0ma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0ma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mz3\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTheta2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'utils' is not defined"
     ]
    }
   ],
   "source": [
    "lambda_=1\n",
    "J, _ = nnCostFunction(initial_nn_params, input_layer_size, hidden_layer_size,\n",
    "                   num_labels, Xtrain, ytrain, lambda_)\n",
    "print('Cost at parameters (randomly initialize): %.6f ' % J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b97aa75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
