{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5378117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split \n",
    "import utils\n",
    "# tells matplotlib to embed plots within the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a766be",
   "metadata": {},
   "source": [
    "# Clasification of adults that have an income larger than 50K\n",
    "\n",
    "# Using a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4468278",
   "metadata": {},
   "source": [
    "### Loading Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2cfc3c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = pd.read_csv('adult_processed_x.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "355c29c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y= pd.read_csv('adult_processed_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5a473d06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 88)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "X= data_x.to_numpy()\n",
    "print(X.shape)\n",
    "print(X.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1c0eaa03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 1)\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "y = data_y.to_numpy()\n",
    "print(y.shape)\n",
    "print(y.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f3344b",
   "metadata": {},
   "source": [
    "## Checking if data is biased \n",
    "\n",
    "The data is biased \n",
    "Only 25% of the data erans more than 50K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4c56eab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples with income above 50K:\t7841\n",
      "Total number of samples :\t\t\t32561\n"
     ]
    }
   ],
   "source": [
    "large_income=y[y==1].size\n",
    "print('Total number of samples with income above 50K:\\t%d' % large_income)\n",
    "print('Total number of samples :\\t\\t\\t%d' % y.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14046f27",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0d40a0e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples:\t32561\n",
      "Number of training samples:\t16280\n",
      "Number of validation samples:\t8140\n",
      "Number of test samples:\t8141\n",
      "(16280, 88)\n",
      "(8140, 88)\n",
      "(8141, 88)\n"
     ]
    }
   ],
   "source": [
    "N = len(X)\n",
    "N_train = int(0.5*N)      # The model  parameters for the network are adjusted using this set\n",
    "N_val = int(0.25*N) # Use to tune parameters in the model. And avoid overfitting to the trainning set.  \n",
    "N_test = N-N_train-N_val\n",
    "\n",
    "# set random seed:\n",
    "np.random.seed(0) \n",
    "\n",
    "# create a random permutation for splitting into training, validation and test\n",
    "randperm = np.random.permutation(N)\n",
    "\n",
    "# split into training and test\n",
    "train_idx = randperm[:N_train]\n",
    "val_idx = randperm[N_train:(N_train+N_val)]\n",
    "test_idx = randperm[(N_train+N_val):]\n",
    "\n",
    "Xtrain,Xval, Xtest = X[train_idx, :],X[val_idx, :], X[test_idx, :]\n",
    "ytrain,yval, ytest = y[train_idx], y[val_idx] , y[test_idx]\n",
    "\n",
    "print('Total number of samples:\\t%d' % N)\n",
    "print('Number of training samples:\\t%d' % N_train)\n",
    "print('Number of validation samples:\\t%d' % N_val)\n",
    "print('Number of test samples:\\t%d' % N_test)\n",
    "print(Xtrain.shape)\n",
    "print(Xval.shape)\n",
    "print(Xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd131d1",
   "metadata": {},
   "source": [
    "## Model representation\n",
    "\n",
    "Our neural network is shown in the following figure.\n",
    "\n",
    "It has 3 layers - an input layer, a hidden layer and an output layer.\n",
    "- Input layer has 88 layer units.\n",
    "- Hidden layer 88 layer units.\n",
    "- Output layer has 2 layer units. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5abfed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_size  = Xtrain.shape[1]  \n",
    "hidden_layer_size = input_layer_size   \n",
    "num_labels = 1          # where 1 means (income => 50k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b5235a",
   "metadata": {},
   "source": [
    "## Random Initialization of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "09162956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== MY CODE HERE ASSIG.4 ======================\n",
    "\n",
    "def randInitializeWeights(L_in, L_out, epsilon_init=0.12):\n",
    "    # Assignment 4\n",
    "    W = np.zeros((L_out, 1 + L_in))\n",
    "    # ====================== MY CODE HERE ======================\n",
    "    W = np.random.rand(L_out, 1 + L_in) * 2 * epsilon_init - epsilon_init\n",
    "    # ============================================================\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "debd4385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== MY CODE HERE ASSIG.4 ======================\n",
    "\n",
    "initial_Theta1 = randInitializeWeights(input_layer_size, hidden_layer_size)\n",
    "initial_Theta2 = randInitializeWeights(hidden_layer_size, num_labels)\n",
    "# Unroll parameters\n",
    "initial_nn_params = np.concatenate([initial_Theta1.ravel(), initial_Theta2.ravel()], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52b9d0e",
   "metadata": {},
   "source": [
    "## Feedforward and cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b17f2064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== MY CODE HERE ASSIG.4 ======================\n",
    "def matrix_of_y(y,num_labels):\n",
    "    n = y.shape[0]\n",
    "    y_v = np.zeros([n,num_labels])\n",
    "    if(y_v.shape[1]==1):\n",
    "        return y\n",
    "    else:\n",
    "        for r in range (n):\n",
    "            y_v[r,y[r]] = 1\n",
    "        return  y_v  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5da385c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== MY CODE HERE ASSIG.3 ======================\n",
    "def sigmoid(z):\n",
    "    z = np.array(z)\n",
    "    g = np.reciprocal((np.exp(z*-1))+1)\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c7fe4e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== MY CODE HERE ASSIG.4 ======================\n",
    "def sigmoidGradient(z):\n",
    "    \n",
    "    g = np.zeros(z.shape)\n",
    "    g_t = sigmoid(z)\n",
    "    g= g_t*(1-g_t)\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0f3572e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== MY CODE HERE ASSIG.4 ADAPTED======================\n",
    "def nnCostFunction(nn_params,\n",
    "                   input_layer_size,\n",
    "                   hidden_layer_size,\n",
    "                   num_labels,\n",
    "                   X, y, lambda_=0.0):\n",
    "    \n",
    "    Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)],\n",
    "                        (hidden_layer_size, (input_layer_size + 1)))\n",
    "\n",
    "    Theta2 = np.reshape(nn_params[(hidden_layer_size * (input_layer_size + 1)):],\n",
    "                        (num_labels, (hidden_layer_size + 1)))\n",
    "\n",
    "    m = y.size\n",
    "    J = 0\n",
    "    Theta1_grad = np.zeros(Theta1.shape)\n",
    "    Theta2_grad = np.zeros(Theta2.shape)\n",
    "\n",
    "    \n",
    "    # ====================== MY CODE HERE ASSIG.4======================\n",
    "    #Calculate hypothesis \n",
    "    a1 = np.concatenate([np.ones((m, 1)), X], axis=1) # add x0 = 1\n",
    "    z2 = np.matmul(Theta1,a1.T)\n",
    "    a2 = sigmoid(z2)\n",
    "    a2 = np.concatenate([np.ones((1, a2.shape[1])), a2], axis=0)\n",
    "    z3 = np.matmul(Theta2,(a2))\n",
    "    a3 = sigmoid(z3)\n",
    "    hyp = a3.T\n",
    "    y_v = matrix_of_y(y,num_labels)\n",
    "\n",
    "    #Calculate cost function. \n",
    "    J = (-1 / m) * np.sum((np.log(hyp) * y_v) + np.log(1 - hyp) * (1 - y_v)) \n",
    "\n",
    "    #Calculate regularized cost function.\n",
    "    temp_theta1 = Theta1[:,1:]\n",
    "    temp_theta2 = Theta2[:,1:]\n",
    "\n",
    "    J_reg_factor = (lambda_/(2*m))*(np.sum(np.square(temp_theta1))+np.sum(np.square(temp_theta2)))\n",
    "    J_reg = J+J_reg_factor\n",
    "    \n",
    "    delta_3 = hyp - y_v\n",
    "    delta_2 = delta_3.dot(Theta2)[:, 1:] * sigmoidGradient(a1.dot(Theta1.T))\n",
    "\n",
    "    Delta1 = delta_2.T.dot(a1)\n",
    "    Delta2 = delta_3.T.dot(a2.T)\n",
    "    \n",
    "    # Add regularization to gradient\n",
    "    Theta1_grad = (1 / m) * Delta1\n",
    "    Theta1_grad[:, 1:] = Theta1_grad[:, 1:] + (lambda_ / m) * Theta1[:, 1:]\n",
    "    \n",
    "    Theta2_grad = (1 / m) * Delta2\n",
    "    Theta2_grad[:, 1:] = Theta2_grad[:, 1:] + (lambda_ / m) * Theta2[:, 1:]\n",
    "      \n",
    "    grad = np.concatenate([Theta1_grad.ravel(), Theta2_grad.ravel()])\n",
    "    \n",
    "    return J_reg, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aba86d2",
   "metadata": {},
   "source": [
    "### Test Gradient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d8c6dba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00927825 -0.00927825]\n",
      " [-0.00559136 -0.00559136]\n",
      " [-0.02017486 -0.02017486]\n",
      " [-0.00585433 -0.00585433]\n",
      " [ 0.00889912  0.00889912]\n",
      " [ 0.01315402  0.01315402]\n",
      " [-0.01049831 -0.01049831]\n",
      " [-0.01910997 -0.01910997]\n",
      " [-0.00836011 -0.00836011]\n",
      " [ 0.01976123  0.01976123]\n",
      " [ 0.00811587  0.00811587]\n",
      " [-0.01515689 -0.01515689]\n",
      " [ 0.00762814  0.00762814]\n",
      " [ 0.00827936  0.00827936]\n",
      " [ 0.02014747  0.02014747]\n",
      " [ 0.00315079  0.00315079]\n",
      " [-0.00674798 -0.00674798]\n",
      " [-0.0109273  -0.0109273 ]\n",
      " [ 0.01262954  0.01262954]\n",
      " [ 0.01809234  0.01809234]\n",
      " [ 0.31454497  0.31454497]\n",
      " [ 0.14895477  0.14895477]\n",
      " [ 0.17770766  0.17770766]\n",
      " [ 0.14745891  0.14745891]\n",
      " [ 0.15953087  0.15953087]\n",
      " [ 0.14381027  0.14381027]\n",
      " [ 0.11105659  0.11105659]\n",
      " [ 0.03839516  0.03839516]\n",
      " [ 0.0775739   0.0775739 ]\n",
      " [ 0.03592373  0.03592373]\n",
      " [ 0.07350885  0.07350885]\n",
      " [ 0.03392626  0.03392626]\n",
      " [ 0.0974007   0.0974007 ]\n",
      " [ 0.04486928  0.04486928]\n",
      " [ 0.05899539  0.05899539]\n",
      " [ 0.03843063  0.03843063]\n",
      " [ 0.06015138  0.06015138]\n",
      " [ 0.03153997  0.03153997]]\n",
      "The above two columns you get should be very similar.\n",
      "(Left-Your Numerical Gradient, Right-Analytical Gradient)\n",
      "\n",
      "If your backpropagation implementation is correct, then \n",
      "the relative difference will be small (less than 1e-9). \n",
      "Relative Difference: 2.32956e-11\n"
     ]
    }
   ],
   "source": [
    "lambda_=1\n",
    "utils.checkNNGradients(nnCostFunction, lambda_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ef0ad5",
   "metadata": {},
   "source": [
    "## Learning parameters using `scipy.optimize.minimize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79893533",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
